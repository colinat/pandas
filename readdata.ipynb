{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "economic-groove",
   "metadata": {},
   "source": [
    "# Creating, Reading and Writing Data\n",
    "---\n",
    "\n",
    "In this notebook, you'll learn about pandas, the most popular Python library for data analysis.\n",
    "\n",
    "pandas contains data structures and data manipulation tools designed to make data cleaning and analysis fast and easy in Python. It is often used in tandem with numerical computing tools like *NumPy* and *SciPy*, analytical libraries - *statsmodels* and *scikit-learn* - as well as data visualisation libraries like *matplotlib*. Compared to *NumPy* which is more suited for numerical array data, *pandas* is designed for working with tabular or heterogeneous data.\n",
    "\n",
    "To better appreciate the use of *pandas*, I will introduce its two workhorse data structures - *Series* and *DataFrame*.\n",
    "\n",
    "Firstly, we will need to import `pandas` library before proceeding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "surgical-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-quarter",
   "metadata": {},
   "source": [
    "## Creating data\n",
    "\n",
    "There are two core objects in pandas: the **DataFrame** and the **Series**.\n",
    "\n",
    "A DataFrame is a table. It contains an array of individual entries, each of which has a certain value. Each entry corresponds to a row (or record) and a column.\n",
    "\n",
    "For example, consider the following simple DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "accomplished-amendment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Yes</th>\n",
       "      <th>No</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Yes   No\n",
       "0   50  131\n",
       "1   21    2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Yes': [50, 21], 'No': [131, 2]})  # pass in dictionary as parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-niger",
   "metadata": {},
   "source": [
    "***Note***: *in Jupyter notebook, `pandas` DataFrame objects will be displayed as a more browser-friendly HTML table as an output.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-commissioner",
   "metadata": {},
   "source": [
    "In this example, the \"0, No\" entry has the value of 131. The \"0, Yes\" entry has a value of 50, and so on.\n",
    "\n",
    "DataFrame entries are not limited to integers. For instance, here's a DataFrame whose values are strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pediatric-julian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bob</th>\n",
       "      <th>Sue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I liked it.</td>\n",
       "      <td>Pretty good.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It was awful.</td>\n",
       "      <td>Bland.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Bob           Sue\n",
       "0    I liked it.  Pretty good.\n",
       "1  It was awful.        Bland."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Bob': ['I liked it.', 'It was awful.'], 'Sue': ['Pretty good.', 'Bland.']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-daughter",
   "metadata": {},
   "source": [
    "We are using the `pd.DataFrame()` constructor to generate these DataFrame objects. The syntax for declaring a new one is a dictionary whose keys are the column names (Bob and Sue in this example), and whose values are a list of entries. This is the standard way of constructing a new DataFrame, and the one you are most likely to encounter.\n",
    "\n",
    "The dictionary-list constructor assigns values to the column labels, but just uses an ascending count from 0 (0, 1, 2, 3, ...) for the row labels. Sometimes this is OK, but oftentimes we will want to assign these labels ourselves.\n",
    "\n",
    "The list of row labels used in a DataFrame is known as an **Index**. We can assign values to it by using an index parameter in our constructor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "precious-maldives",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bob</th>\n",
       "      <th>Sue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Product A</th>\n",
       "      <td>I liked it.</td>\n",
       "      <td>Pretty good.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product B</th>\n",
       "      <td>It was awful.</td>\n",
       "      <td>Bland.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Bob           Sue\n",
       "Product A    I liked it.  Pretty good.\n",
       "Product B  It was awful.        Bland."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Bob': ['I liked it.', 'It was awful.'], \n",
    "              'Sue': ['Pretty good.', 'Bland.']},\n",
    "             index=['Product A', 'Product B'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-picking",
   "metadata": {},
   "source": [
    "Another common form of data passed to a DataFrame is a nested dict of dicts. This makes it convenient to convert data in such format to a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "warming-soldier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bob</th>\n",
       "      <th>Sue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Product A</th>\n",
       "      <td>I liked it.</td>\n",
       "      <td>Pretty good.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product B</th>\n",
       "      <td>It was awful.</td>\n",
       "      <td>Bland.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Bob           Sue\n",
       "Product A    I liked it.  Pretty good.\n",
       "Product B  It was awful.        Bland."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Bob': {'Product A': 'I liked it.', 'Product B': 'It was awful.'}, \n",
    "              'Sue': {'Product A': 'Pretty good.', 'Product B': 'Bland.'},\n",
    "             })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-bicycle",
   "metadata": {},
   "source": [
    "Table below lists possible data inputs to DataFrame constructor:\n",
    "\n",
    "**Type** | **Notes**\n",
    "--- | ---\n",
    "2D ndarray | A matrix of data, passing optional row and column labels\n",
    "`dict` of arrays, lists or tuples | Each sequence becomes a column in the DataFrame; all sequences must be the same length\n",
    "NumPy structured/record array | Treated as the \"dict of arrays\" case\n",
    "`dict` of Series | Each value becomes a column; indexes from each Series are unioned together to form the result's row index if no explicit index is passed.\n",
    "`dict` of `dicts` |  Each inner dict becomes a column; keys are unioned to form the row index as in the \"dict of Series\" case\n",
    "List of `dicts` or Series | Each item becomes a row in the DataFrame; union of dict keys or Series indexes become the DataFrame's column labels\n",
    "List of lists or tuples | Treated as the \"2D ndarray\" case\n",
    "Another DataFrame | The DataFrame's indexes are used unless different ones are passed\n",
    "NumPy MaskedArray | Like the \"2D ndaaray\" case except masked values become NA/missing in the DataFrame result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-forestry",
   "metadata": {},
   "source": [
    "## Series\n",
    "\n",
    "A Series, by contrast, is a sequence of data values. If a DataFrame is a table, a Series is a list. And in fact you can create one with nothing more than a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "announced-measure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    4\n",
       "4    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-cattle",
   "metadata": {},
   "source": [
    "A Series is, in essence, a single column of a DataFrame. So you can assign column values to the Series the same way as before, using an index parameter. However, a Series does not have a column name, it only has one overall name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "toxic-interference",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2015 Sales    30\n",
       "2016 Sales    35\n",
       "2017 Sales    40\n",
       "Name: Product A, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([30, 35, 40], index=['2015 Sales', '2016 Sales', '2017 Sales'], name='Product A')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-spectrum",
   "metadata": {},
   "source": [
    "Getting the list of index values from a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "developing-gabriel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['2015 Sales', '2016 Sales', '2017 Sales'], dtype='object')\n",
      "<class 'pandas.core.indexes.base.Index'>\n",
      "['2015 Sales', '2016 Sales', '2017 Sales']\n"
     ]
    }
   ],
   "source": [
    "s_data = pd.Series([30, 35, 40], index=['2015 Sales', '2016 Sales', '2017 Sales'], name='Product A')\n",
    "\n",
    "print(s_data.index)\n",
    "print(type(s_data.index))\n",
    "\n",
    "print(list(s_data.index))  # convert to list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-illinois",
   "metadata": {},
   "source": [
    "We can get values of a Series in an array form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "deluxe-popularity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30 35 40]\n",
      "<class 'numpy.ndarray'>\n",
      "[30, 35, 40]\n"
     ]
    }
   ],
   "source": [
    "print(s_data.values)        # this is in numpy array format\n",
    "print(type(s_data.values))\n",
    "\n",
    "print(list(s_data.values))  # convert to list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-clear",
   "metadata": {},
   "source": [
    "***Note:*** *ndarray is a type of object under numpy class. It is designed for greater efficiency in mind for storing and manipulating data compared to other built-in Python data structures.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-shoulder",
   "metadata": {},
   "source": [
    "## Arithmethic Operations on Series\n",
    "\n",
    "A useful Series feature is that it automatically aligns by index label in arithmetic operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "hydraulic-guarantee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2015 Sales    45\n",
       "2016 Sales    55\n",
       "2017 Sales    75\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_data2 = pd.Series([15, 20, 35], index=['2015 Sales', '2016 Sales', '2017 Sales'], name='Product B')\n",
    "\n",
    "s_data + s_data2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-medicine",
   "metadata": {},
   "source": [
    "What if we add two series with some differences in their indexes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "static-flavor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2015 Sales     NaN\n",
       "2016 Sales    40.0\n",
       "2017 Sales    50.0\n",
       "2018 Sales     NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_data3 = pd.Series([5, 10, 35], index=['2016 Sales', '2017 Sales', '2018 Sales'], name='Product C')\n",
    "\n",
    "s_data + s_data3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-mediterranean",
   "metadata": {},
   "source": [
    "`2015 Sales` and `2018 Sales` now have missing values (represented by `NaN`) as `2015 Sales` is not present in `s_data3` whereas `2018 Sales` is not present in `s_data`. The resulting output is a union of the index pairs when adding objects with different indexes. \n",
    "\n",
    "To understand why this happens, remember `NaN` is a special value in Python whereby when you perform any arithmethic operations on it, the result will always be `NaN`. For the case of `2015 Sales` in the above example, the operation is basically summing `2015 Sales` value in `s_data` (30) to the corresponding value in `s_data3`, which is missing or `NaN` value. Thus the result will be `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "atlantic-massage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# illustration of NaN value\n",
    "a = float(\"NaN\")\n",
    "a ** 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-highlight",
   "metadata": {},
   "source": [
    "The Series and the DataFrame are intimately related. It's helpful to think of a DataFrame as actually being just a bunch of Series \"glued together\". We'll see more of this in the next section in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-melbourne",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "lightweight-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews = pd.read_csv(\"../../datasets/wine-reviews/winemag-data-130k-v2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-motor",
   "metadata": {},
   "source": [
    "We can use the `shape` attribute to check how large the resulting DataFrame is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sitting-elephant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129971, 14)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_reviews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-transmission",
   "metadata": {},
   "source": [
    "So our new DataFrame has 130,000 records split across 14 different columns. That's almost 2 million entries!\n",
    "\n",
    "We can examine the contents of the resultant DataFrame using the `head()` command, which grabs the first five rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "earned-contemporary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>taster_twitter_handle</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
       "      <td>Vulkà Bianco</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>Etna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kerin O’Keefe</td>\n",
       "      <td>@kerinokeefe</td>\n",
       "      <td>Nicosia 2013 Vulkà Bianco  (Etna)</td>\n",
       "      <td>White Blend</td>\n",
       "      <td>Nicosia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>Avidagos</td>\n",
       "      <td>87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Douro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>@vossroger</td>\n",
       "      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n",
       "      <td>Portuguese Red</td>\n",
       "      <td>Quinta dos Avidagos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>@paulgwine</td>\n",
       "      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n",
       "      <td>Pinot Gris</td>\n",
       "      <td>Rainstorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>Reserve Late Harvest</td>\n",
       "      <td>87</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Lake Michigan Shore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alexander Peartree</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St. Julian 2013 Reserve Late Harvest Riesling ...</td>\n",
       "      <td>Riesling</td>\n",
       "      <td>St. Julian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>Vintner's Reserve Wild Child Block</td>\n",
       "      <td>87</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>@paulgwine</td>\n",
       "      <td>Sweet Cheeks 2012 Vintner's Reserve Wild Child...</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Sweet Cheeks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   country                                        description  \\\n",
       "0           0     Italy  Aromas include tropical fruit, broom, brimston...   \n",
       "1           1  Portugal  This is ripe and fruity, a wine that is smooth...   \n",
       "2           2        US  Tart and snappy, the flavors of lime flesh and...   \n",
       "3           3        US  Pineapple rind, lemon pith and orange blossom ...   \n",
       "4           4        US  Much like the regular bottling from 2012, this...   \n",
       "\n",
       "                          designation  points  price           province  \\\n",
       "0                        Vulkà Bianco      87    NaN  Sicily & Sardinia   \n",
       "1                            Avidagos      87   15.0              Douro   \n",
       "2                                 NaN      87   14.0             Oregon   \n",
       "3                Reserve Late Harvest      87   13.0           Michigan   \n",
       "4  Vintner's Reserve Wild Child Block      87   65.0             Oregon   \n",
       "\n",
       "              region_1           region_2         taster_name  \\\n",
       "0                 Etna                NaN       Kerin O’Keefe   \n",
       "1                  NaN                NaN          Roger Voss   \n",
       "2    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
       "3  Lake Michigan Shore                NaN  Alexander Peartree   \n",
       "4    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
       "\n",
       "  taster_twitter_handle                                              title  \\\n",
       "0          @kerinokeefe                  Nicosia 2013 Vulkà Bianco  (Etna)   \n",
       "1            @vossroger      Quinta dos Avidagos 2011 Avidagos Red (Douro)   \n",
       "2           @paulgwine       Rainstorm 2013 Pinot Gris (Willamette Valley)   \n",
       "3                   NaN  St. Julian 2013 Reserve Late Harvest Riesling ...   \n",
       "4           @paulgwine   Sweet Cheeks 2012 Vintner's Reserve Wild Child...   \n",
       "\n",
       "          variety               winery  \n",
       "0     White Blend              Nicosia  \n",
       "1  Portuguese Red  Quinta dos Avidagos  \n",
       "2      Pinot Gris            Rainstorm  \n",
       "3        Riesling           St. Julian  \n",
       "4      Pinot Noir         Sweet Cheeks  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-actor",
   "metadata": {},
   "source": [
    "The `pd.read_csv()` function is well-endowed, with over 30 optional parameters you can specify. For example, you can see in this dataset that the CSV file has a built-in index, which pandas did not pick up on automatically. To make pandas use that column for the `index` (instead of creating a new one from scratch), we can specify an index_col.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "looking-australia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>taster_twitter_handle</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Italy</td>\n",
       "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
       "      <td>Vulkà Bianco</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>Etna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kerin O’Keefe</td>\n",
       "      <td>@kerinokeefe</td>\n",
       "      <td>Nicosia 2013 Vulkà Bianco  (Etna)</td>\n",
       "      <td>White Blend</td>\n",
       "      <td>Nicosia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>Avidagos</td>\n",
       "      <td>87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Douro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>@vossroger</td>\n",
       "      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n",
       "      <td>Portuguese Red</td>\n",
       "      <td>Quinta dos Avidagos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>@paulgwine</td>\n",
       "      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n",
       "      <td>Pinot Gris</td>\n",
       "      <td>Rainstorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>Reserve Late Harvest</td>\n",
       "      <td>87</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Lake Michigan Shore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alexander Peartree</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St. Julian 2013 Reserve Late Harvest Riesling ...</td>\n",
       "      <td>Riesling</td>\n",
       "      <td>St. Julian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>Vintner's Reserve Wild Child Block</td>\n",
       "      <td>87</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>@paulgwine</td>\n",
       "      <td>Sweet Cheeks 2012 Vintner's Reserve Wild Child...</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Sweet Cheeks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country                                        description  \\\n",
       "0     Italy  Aromas include tropical fruit, broom, brimston...   \n",
       "1  Portugal  This is ripe and fruity, a wine that is smooth...   \n",
       "2        US  Tart and snappy, the flavors of lime flesh and...   \n",
       "3        US  Pineapple rind, lemon pith and orange blossom ...   \n",
       "4        US  Much like the regular bottling from 2012, this...   \n",
       "\n",
       "                          designation  points  price           province  \\\n",
       "0                        Vulkà Bianco      87    NaN  Sicily & Sardinia   \n",
       "1                            Avidagos      87   15.0              Douro   \n",
       "2                                 NaN      87   14.0             Oregon   \n",
       "3                Reserve Late Harvest      87   13.0           Michigan   \n",
       "4  Vintner's Reserve Wild Child Block      87   65.0             Oregon   \n",
       "\n",
       "              region_1           region_2         taster_name  \\\n",
       "0                 Etna                NaN       Kerin O’Keefe   \n",
       "1                  NaN                NaN          Roger Voss   \n",
       "2    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
       "3  Lake Michigan Shore                NaN  Alexander Peartree   \n",
       "4    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
       "\n",
       "  taster_twitter_handle                                              title  \\\n",
       "0          @kerinokeefe                  Nicosia 2013 Vulkà Bianco  (Etna)   \n",
       "1            @vossroger      Quinta dos Avidagos 2011 Avidagos Red (Douro)   \n",
       "2           @paulgwine       Rainstorm 2013 Pinot Gris (Willamette Valley)   \n",
       "3                   NaN  St. Julian 2013 Reserve Late Harvest Riesling ...   \n",
       "4           @paulgwine   Sweet Cheeks 2012 Vintner's Reserve Wild Child...   \n",
       "\n",
       "          variety               winery  \n",
       "0     White Blend              Nicosia  \n",
       "1  Portuguese Red  Quinta dos Avidagos  \n",
       "2      Pinot Gris            Rainstorm  \n",
       "3        Riesling           St. Julian  \n",
       "4      Pinot Noir         Sweet Cheeks  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_reviews = pd.read_csv(\"../../datasets/wine-reviews/winemag-data-130k-v2.csv\", index_col=0)\n",
    "wine_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-scout",
   "metadata": {},
   "source": [
    "By default, `read_csv()` will read the first row as the header row. However, a file will not always have a header row. Consider this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "alpha-london",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,2,3,4,hello\r\n",
      "5,6,7,8,world\r\n",
      "9,10,11,12,foo\r\n"
     ]
    }
   ],
   "source": [
    "!cat examples/ex2.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-execution",
   "metadata": {},
   "source": [
    "***Note:*** *Using an exclamation mark(!) before the command will pass the command to the underlying shell (not to the Python interpreter). In the example above, I used Linux `cat` command to print the raw contents of the file to the screen. For Windows systems, you can use `type` instead of `cat` to achieve the same effect*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-phenomenon",
   "metadata": {},
   "source": [
    "To read the file using `read_csv()`, there are several options you can configure. You can allow pandas to assign default column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "unlike-radiation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3      4\n",
       "0  1   2   3   4  hello\n",
       "1  5   6   7   8  world\n",
       "2  9  10  11  12    foo"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('examples/ex2.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-tokyo",
   "metadata": {},
   "source": [
    "`pd.read_csv()` method also allows to take in a regular expression for the delimiter as a parameter. This is useful for handling files which might not have a fixed delimiter or using whitespace to separate the fields. Consider this file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "declared-alarm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            A         B         C\r\n",
      "aaa -0.264438 -1.026059 -0.619500\r\n",
      "bbb  0.927272  0.302904 -0.032399\r\n",
      "ccc -0.264273 -0.386314 -0.217601\r\n",
      "ddd -0.871858 -0.348382  1.100491\r\n"
     ]
    }
   ],
   "source": [
    "!cat examples/ex3.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "heavy-trustee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aaa</th>\n",
       "      <td>-0.264438</td>\n",
       "      <td>-1.026059</td>\n",
       "      <td>-0.619500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbb</th>\n",
       "      <td>0.927272</td>\n",
       "      <td>0.302904</td>\n",
       "      <td>-0.032399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ccc</th>\n",
       "      <td>-0.264273</td>\n",
       "      <td>-0.386314</td>\n",
       "      <td>-0.217601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ddd</th>\n",
       "      <td>-0.871858</td>\n",
       "      <td>-0.348382</td>\n",
       "      <td>1.100491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            A         B         C\n",
       "aaa -0.264438 -1.026059 -0.619500\n",
       "bbb  0.927272  0.302904 -0.032399\n",
       "ccc -0.264273 -0.386314 -0.217601\n",
       "ddd -0.871858 -0.348382  1.100491"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('examples/ex3.txt', sep='\\s+')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-program",
   "metadata": {},
   "source": [
    "pandas features a number of functions for reading tabular data as a DataFrame object. Table below summarises some of them, including `read_csv`\n",
    "  \n",
    "  **Function** | **Description**\n",
    "  --- | ---\n",
    "  `read_csv` | Load delimited data from a file, URL, or file-like object; use comma as default delimiter\n",
    "  `read_fwf` | Read data in fixed-width column format (.e., no delimiters)\n",
    "  `read_clipboard` | Version of `read_csv` that reads data from the clipboard; useful for converting tables from web pages\n",
    "  `read_excel` | Read tabular data from an Excel XLS or XLSX file\n",
    "  `read_hdf` | Read HDF5 files written by pandas\n",
    "  `read_html` | Read all tables found in the given HTML document\n",
    "  `read_json` | Read data from a JSON (JavaScript Object Notation) string representation\n",
    "  `read_msgpack` | Read pandas data encoded using the MessagePack binary format\n",
    "  `read_pickle` | Read an arbitrary object stored in Python pickle format\n",
    "  `read_sas` | Read a SAS dataset stored in one of the SAS system's custom storage formats\n",
    "  `read_sql` | Read the results of a SQL query (using SQLAlchemy) as a pandas DataFrame\n",
    "  `read_stata` | Read a dataset from Stata file format\n",
    "  `read_feather` | Read the Feather binary file format\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-output",
   "metadata": {},
   "source": [
    "## Writing Data\n",
    "\n",
    "Data can also be exported to a delimited format. Using DataFrame's `to_csv()` method, we can write the data out to a comma-separated file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "juvenile-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'Bob': {'Product A': 'I liked it.', 'Product B': 'It was awful.'}, \n",
    "              'Sue': {'Product A': 'Pretty good.', 'Product B': 'Bland.'},\n",
    "             })\n",
    "\n",
    "data.to_csv('examples/out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "round-success",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",Bob,Sue\r\n",
      "Product A,I liked it.,Pretty good.\r\n",
      "Product B,It was awful.,Bland.\r\n"
     ]
    }
   ],
   "source": [
    "# invoking shell command to display file contents\n",
    "!cat examples/out.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-inspector",
   "metadata": {},
   "source": [
    "Following sections include more advanced lessons on reading data that could come in other forms apart from csv file. You can skip to the next lesson on [indexing, selecting and assigning](https://github.com/colintwh/python-analysis/blob/master/indexing.ipynb) or carry on if you wish to learn more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-cursor",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## JSON data\n",
    "\n",
    "JSON (short for JavaScript Object Notation) has become one of the standard formats for sending data by HTTP request between web browsers and other applications. It is a much more free-form data format than a tabular text form like CSV. Here is a JSON example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "expected-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = \"\"\"\n",
    "{\"name\": \"Wes\",\n",
    " \"places_lived\": [\"United States\", \"Spain\", \"Germany\"],\n",
    " \"pet\": null,\n",
    " \"siblings\": [{\"name\": \"Scott\", \"age\": 30, \"pets\": [\"Zeus\", \"Zuko\"]},\n",
    "              {\"name\": \"Katie\", \"age\": 38, \"pets\": [\"Sixes\", \"Stache\", \"Cisco\"]}]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-verse",
   "metadata": {},
   "source": [
    "JSON is very nearly valid Python code, but with the exception of its null value null and some other nuances (e.g. disallowing trailing commas at the end of lists). The basic types are objects (dicts), arrays (lists), strings, numbers, booleans, and nulls. All of the keys in an object must be strings. \n",
    "\n",
    "There are several Python libraries for reading and writing JSON data. I'll use `json` here, as it is built into the Python standard library. To convert a JSON string to Python form, use `json.loads`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "designed-aurora",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Wes',\n",
       " 'places_lived': ['United States', 'Spain', 'Germany'],\n",
       " 'pet': None,\n",
       " 'siblings': [{'name': 'Scott', 'age': 30, 'pets': ['Zeus', 'Zuko']},\n",
       "  {'name': 'Katie', 'age': 38, 'pets': ['Sixes', 'Stache', 'Cisco']}]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "result = json.loads(obj)  # converts JSON to Python 'dict'\n",
    "result "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-lotus",
   "metadata": {},
   "source": [
    "`json.dumps`, on the other hand, converts a Python object back to JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adaptive-opposition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"Wes\", \"places_lived\": [\"United States\", \"Spain\", \"Germany\"], \"pet\": null, \"siblings\": [{\"name\": \"Scott\", \"age\": 30, \"pets\": [\"Zeus\", \"Zuko\"]}, {\"name\": \"Katie\", \"age\": 38, \"pets\": [\"Sixes\", \"Stache\", \"Cisco\"]}]}\n"
     ]
    }
   ],
   "source": [
    "asjson = json.dumps(result)\n",
    "print(asjson)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-merit",
   "metadata": {},
   "source": [
    "The `pandas.read_json` can automatically convert JSON datasets in specific arrangements into a Series or DataFrame. The default options for `pandas.read_json` assume each object in the JSON array is a row in the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "passing-berlin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"a\": 1, \"b\": 2, \"c\": 3},\r\n",
      " {\"a\": 4, \"b\": 5, \"c\": 6},\r\n",
      " {\"a\": 7, \"b\": 8, \"c\": 9}]\r\n"
     ]
    }
   ],
   "source": [
    "!cat examples/example.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "major-scott",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b  c\n",
       "0  1  2  3\n",
       "1  4  5  6\n",
       "2  7  8  9"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json('examples/example.json')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-lending",
   "metadata": {},
   "source": [
    "For exporting data from pandas to JSON, one way is to use the `to_json` methods on Series and DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "spanish-excitement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"a\":{\"0\":1,\"1\":4,\"2\":7},\"b\":{\"0\":2,\"1\":5,\"2\":8},\"c\":{\"0\":3,\"1\":6,\"2\":9}}\n"
     ]
    }
   ],
   "source": [
    "print(\"{}\".format(data.to_json()))  # convert to JSON - all in one record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "silent-henry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[{\"a\":1,\"b\":2,\"c\":3},{\"a\":4,\"b\":5,\"c\":6},{\"a\":7,\"b\":8,\"c\":9}]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n{}\".format(data.to_json(orient='records')))  # convert to JSON - preserve multiple records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-asset",
   "metadata": {},
   "source": [
    "## XML and HTML: Web Scraping\n",
    "\n",
    "Python has many libraries for reading and writing data in the ubiquitous HTML and XML formats. Example libraries include lxml, Beautiful Soup, and html5lib. While lxml is comparatively much faster in general, the other libraries can better handle malformed HTML and XML files. \n",
    "\n",
    "`pandas` has a built-in function, `read_html()`, which uses libraries like lxml and Beautiful Soup to automatically parse tables out of HTML files as DataFrame objects. To show how this works, firstly we'll need a HTML file from [here](https://www.fdic.gov/resources/resolutions/bank-failures/failed-bank-list/banklist.html)) and to install some additional libraries (namely `lxml`, `beautifulsoup4` and `html5lib`) used by `read_html()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "turned-federation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                             Bank Name           City  ST   CERT  \\\n",
       " 0                 The First State Bank  Barboursville  WV  14361   \n",
       " 1                   Ericson State Bank        Ericson  NE  18265   \n",
       " 2     City National Bank of New Jersey         Newark  NJ  21111   \n",
       " 3                        Resolute Bank         Maumee  OH  58317   \n",
       " 4                Louisa Community Bank         Louisa  KY  58112   \n",
       " ..                                 ...            ...  ..    ...   \n",
       " 556                 Superior Bank, FSB       Hinsdale  IL  32646   \n",
       " 557                Malta National Bank          Malta  OH   6629   \n",
       " 558    First Alliance Bank & Trust Co.     Manchester  NH  34264   \n",
       " 559  National State Bank of Metropolis     Metropolis  IL   3815   \n",
       " 560                   Bank of Honolulu       Honolulu  HI  21029   \n",
       " \n",
       "                    Acquiring Institution       Closing Date  \n",
       " 0                         MVB Bank, Inc.      April 3, 2020  \n",
       " 1             Farmers and Merchants Bank  February 14, 2020  \n",
       " 2                        Industrial Bank   November 1, 2019  \n",
       " 3                     Buckeye State Bank   October 25, 2019  \n",
       " 4      Kentucky Farmers Bank Corporation   October 25, 2019  \n",
       " ..                                   ...                ...  \n",
       " 556                Superior Federal, FSB      July 27, 2001  \n",
       " 557                    North Valley Bank        May 3, 2001  \n",
       " 558  Southern New Hampshire Bank & Trust   February 2, 2001  \n",
       " 559              Banterra Bank of Marion  December 14, 2000  \n",
       " 560                   Bank of the Orient   October 13, 2000  \n",
       " \n",
       " [561 rows x 6 columns]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables = pd.read_html('examples/fdic_failed_bank_list.html')  # convert to list of DataFrame objects\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "described-proceeding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bank Name</th>\n",
       "      <th>City</th>\n",
       "      <th>ST</th>\n",
       "      <th>CERT</th>\n",
       "      <th>Acquiring Institution</th>\n",
       "      <th>Closing Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The First State Bank</td>\n",
       "      <td>Barboursville</td>\n",
       "      <td>WV</td>\n",
       "      <td>14361</td>\n",
       "      <td>MVB Bank, Inc.</td>\n",
       "      <td>April 3, 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ericson State Bank</td>\n",
       "      <td>Ericson</td>\n",
       "      <td>NE</td>\n",
       "      <td>18265</td>\n",
       "      <td>Farmers and Merchants Bank</td>\n",
       "      <td>February 14, 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>City National Bank of New Jersey</td>\n",
       "      <td>Newark</td>\n",
       "      <td>NJ</td>\n",
       "      <td>21111</td>\n",
       "      <td>Industrial Bank</td>\n",
       "      <td>November 1, 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Resolute Bank</td>\n",
       "      <td>Maumee</td>\n",
       "      <td>OH</td>\n",
       "      <td>58317</td>\n",
       "      <td>Buckeye State Bank</td>\n",
       "      <td>October 25, 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Louisa Community Bank</td>\n",
       "      <td>Louisa</td>\n",
       "      <td>KY</td>\n",
       "      <td>58112</td>\n",
       "      <td>Kentucky Farmers Bank Corporation</td>\n",
       "      <td>October 25, 2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Bank Name           City  ST   CERT  \\\n",
       "0              The First State Bank  Barboursville  WV  14361   \n",
       "1                Ericson State Bank        Ericson  NE  18265   \n",
       "2  City National Bank of New Jersey         Newark  NJ  21111   \n",
       "3                     Resolute Bank         Maumee  OH  58317   \n",
       "4             Louisa Community Bank         Louisa  KY  58112   \n",
       "\n",
       "               Acquiring Institution       Closing Date  \n",
       "0                     MVB Bank, Inc.      April 3, 2020  \n",
       "1         Farmers and Merchants Bank  February 14, 2020  \n",
       "2                    Industrial Bank   November 1, 2019  \n",
       "3                 Buckeye State Bank   October 25, 2019  \n",
       "4  Kentucky Farmers Bank Corporation   October 25, 2019  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failures = tables[0]  # retrieve DataFrame object in the list\n",
    "failures.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-uganda",
   "metadata": {},
   "source": [
    "## Parsing XML with `lxml.objectify`\n",
    "\n",
    "XML (eXtensible Markup Language) is another common structured data format supporting hierarchical, nested data with metadata. In the earlier example, the `pandas.read_html()` function uses either lxml or Beautiful Soup under the hood to parse data from HTML. We'll look at another example that parses data from a more general XML format from [here](https://data.ny.gov/Transportation/Metropolitan-Transportation-Authority-MTA-Monthly-/5xht-v2bs) that looks like this:\n",
    "\n",
    "```xml\n",
    "<response>\n",
    "<row>\n",
    "<row _id=\"row-3cac_6v3p_924a\" _uuid=\"00000000-0000-0000-FF4E-F08E99D68BA9\" _position=\"0\" _address=\"https://data.ny.gov/resource/zzzz-zzzz/row-3cac_6v3p_924a\">\n",
    "<indicator_sequence>55512</indicator_sequence>\n",
    "<parent_sequence>0</parent_sequence>\n",
    "<agency_name>Metro-North Railroad</agency_name>\n",
    "<indicator_name>Total Ridership </indicator_name>\n",
    "<description>\n",
    "The number of passengers from whom the agency receives a fare (cash, train tickets, time-based passes, etc.) Ridership data is preliminary and subject to revision as well as adjustments warranted by annual audit review.\n",
    "</description>\n",
    "<category>Service Indicators</category>\n",
    "<frequency>M</frequency>\n",
    "<desired_change>U</desired_change>\n",
    "<indicator_unit>-</indicator_unit>\n",
    "<decimal_places>0</decimal_places>\n",
    "<period_year>2008</period_year>\n",
    "<period_month>1</period_month>\n",
    "<ytd_target>6475134.00</ytd_target>\n",
    "<ytd_actual>6618443.00</ytd_actual>\n",
    "<monthly_target>6475134.00</monthly_target>\n",
    "<monthly_actual>6618443.00</monthly_actual>\n",
    "<period>2008-01</period>\n",
    "</row>\n",
    "```\n",
    "\n",
    "Using `lxml.objectify`, we parse the file and get a reference to the root node of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "incredible-opportunity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import objectify\n",
    "\n",
    "path = 'examples/ny_mta_data.xml'\n",
    "parsed = objectify.parse(open(path))\n",
    "root = parsed.getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acute-highlight",
   "metadata": {},
   "source": [
    "For each record, we can populate a dict of tag names (e.g. `ytd_actual`) to data values (excluding a few tags):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bearing-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []    # initialise empty list\n",
    "skip_fields = ['parent_sequence', 'indicator_sequence','desired_change','decimal_places']\n",
    "\n",
    "for elem in root.row.row:   # traverse 2 levels pass response->row->row in xml doc\n",
    "        el_data = {}        \n",
    "        \n",
    "        # we insert each tag and corresponding value in a dictionary before appending the dict entry to list of data\n",
    "        for field in elem.getchildren():   \n",
    "            if field.tag in skip_fields:      # skip those fields earlier list of skip_fields\n",
    "                continue        \n",
    "        \n",
    "            el_data[field.tag] = field.pyval  # extract value\n",
    "        data.append(el_data)                  # append one record each time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-rendering",
   "metadata": {},
   "source": [
    "Lastly, we'll convert this list of dicts into a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "higher-virus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency_name</th>\n",
       "      <th>indicator_name</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "      <th>frequency</th>\n",
       "      <th>indicator_unit</th>\n",
       "      <th>period_year</th>\n",
       "      <th>period_month</th>\n",
       "      <th>ytd_target</th>\n",
       "      <th>ytd_actual</th>\n",
       "      <th>monthly_target</th>\n",
       "      <th>monthly_actual</th>\n",
       "      <th>period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Metro-North Railroad</td>\n",
       "      <td>Total Ridership</td>\n",
       "      <td>The number of passengers from whom the agency ...</td>\n",
       "      <td>Service Indicators</td>\n",
       "      <td>M</td>\n",
       "      <td>-</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>6475134.0</td>\n",
       "      <td>6618443.0</td>\n",
       "      <td>6475134.0</td>\n",
       "      <td>6618443.0</td>\n",
       "      <td>2008-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Metro-North Railroad</td>\n",
       "      <td>Total Ridership</td>\n",
       "      <td>The number of passengers from whom the agency ...</td>\n",
       "      <td>Service Indicators</td>\n",
       "      <td>M</td>\n",
       "      <td>-</td>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>12520602.0</td>\n",
       "      <td>12919928.0</td>\n",
       "      <td>6045468.0</td>\n",
       "      <td>6301485.0</td>\n",
       "      <td>2008-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Metro-North Railroad</td>\n",
       "      <td>Total Ridership</td>\n",
       "      <td>The number of passengers from whom the agency ...</td>\n",
       "      <td>Service Indicators</td>\n",
       "      <td>M</td>\n",
       "      <td>-</td>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>19084109.0</td>\n",
       "      <td>19691414.0</td>\n",
       "      <td>6563507.0</td>\n",
       "      <td>6771486.0</td>\n",
       "      <td>2008-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Metro-North Railroad</td>\n",
       "      <td>Total Ridership</td>\n",
       "      <td>The number of passengers from whom the agency ...</td>\n",
       "      <td>Service Indicators</td>\n",
       "      <td>M</td>\n",
       "      <td>-</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>25895437.0</td>\n",
       "      <td>26650054.0</td>\n",
       "      <td>6811328.0</td>\n",
       "      <td>6958640.0</td>\n",
       "      <td>2008-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Metro-North Railroad</td>\n",
       "      <td>Total Ridership</td>\n",
       "      <td>The number of passengers from whom the agency ...</td>\n",
       "      <td>Service Indicators</td>\n",
       "      <td>M</td>\n",
       "      <td>-</td>\n",
       "      <td>2008</td>\n",
       "      <td>5</td>\n",
       "      <td>32758164.0</td>\n",
       "      <td>33672738.0</td>\n",
       "      <td>6862727.0</td>\n",
       "      <td>7022684.0</td>\n",
       "      <td>2008-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            agency_name    indicator_name  \\\n",
       "0  Metro-North Railroad  Total Ridership    \n",
       "1  Metro-North Railroad  Total Ridership    \n",
       "2  Metro-North Railroad  Total Ridership    \n",
       "3  Metro-North Railroad  Total Ridership    \n",
       "4  Metro-North Railroad  Total Ridership    \n",
       "\n",
       "                                         description            category  \\\n",
       "0  The number of passengers from whom the agency ...  Service Indicators   \n",
       "1  The number of passengers from whom the agency ...  Service Indicators   \n",
       "2  The number of passengers from whom the agency ...  Service Indicators   \n",
       "3  The number of passengers from whom the agency ...  Service Indicators   \n",
       "4  The number of passengers from whom the agency ...  Service Indicators   \n",
       "\n",
       "  frequency indicator_unit  period_year  period_month  ytd_target  ytd_actual  \\\n",
       "0         M              -         2008             1   6475134.0   6618443.0   \n",
       "1         M              -         2008             2  12520602.0  12919928.0   \n",
       "2         M              -         2008             3  19084109.0  19691414.0   \n",
       "3         M              -         2008             4  25895437.0  26650054.0   \n",
       "4         M              -         2008             5  32758164.0  33672738.0   \n",
       "\n",
       "   monthly_target  monthly_actual   period  \n",
       "0       6475134.0       6618443.0  2008-01  \n",
       "1       6045468.0       6301485.0  2008-02  \n",
       "2       6563507.0       6771486.0  2008-03  \n",
       "3       6811328.0       6958640.0  2008-04  \n",
       "4       6862727.0       7022684.0  2008-05  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf = pd.DataFrame(data)\n",
    "perf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-handy",
   "metadata": {},
   "source": [
    "Each XML tag can have metadata too. Consider an HTML link tag, which is also valid XML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "mature-sound",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "tag = '<a href=\"http://www.google.com\">Google</a>'\n",
    "root = objectify.parse(StringIO(tag)).getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "following-saskatchewan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.google.com\n",
      "\n",
      "Google\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"{}\\n\".format(root.get('href')))\n",
    "print(\"{}\\n\".format(root.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-minority",
   "metadata": {},
   "source": [
    "## Binary Data Formats\n",
    "\n",
    "One of the easiest ways to store data (also known as *serialization*) efficiently in binary format is using Python's built-in `pickle` serialization. pandas objects all have a `to_pickle()` method that writes the data to disk in pickle format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "included-mainland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a,b,c,d,message\r\n",
      "1,2,3,4,hello\r\n",
      "5,6,7,8,world\r\n",
      "9,10,11,12,foo\r\n"
     ]
    }
   ],
   "source": [
    "!cat examples/ex1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "portuguese-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.read_csv('examples/ex1.csv')\n",
    "frame.to_pickle('examples/frame_pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-neighbor",
   "metadata": {},
   "source": [
    "You can read any \"pickle\" object stored in a file by using the built-in `pandas.read_pickle()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "motivated-tournament",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a   b   c   d message\n",
       "0  1   2   3   4   hello\n",
       "1  5   6   7   8   world\n",
       "2  9  10  11  12     foo"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle('examples/frame_pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-roots",
   "metadata": {},
   "source": [
    "***Note:*** *`pickle` is only recommended as a short-term storage format. The problem is that it is not guaranteed that the format will be stable over time; an object pickled today may not unpickle with a later version of a library.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-driver",
   "metadata": {},
   "source": [
    "## Reading Microsoft Excel Files\n",
    "\n",
    "pandas also supports reading tabular data stored in Excel 2003 (and higher) files using either the `ExcelFile` class or `pandas.read_excel()` function. Internally these tools used the add-on package `xlrd` and `openpyxl` to read XLS and XLSX files, respectively. These must be installed separately from pandas (using either pip or conda).\n",
    "\n",
    "To use `ExcelFile`, create an instance by passing a path to an `xls` or `xlsx` file. Data stored in a sheet can then be read into DataFrame with parse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "occasional-mobile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a   b   c   d message\n",
       "0  1   2   3   4   hello\n",
       "1  5   6   7   8   world\n",
       "2  9  10  11  12     foo"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlsx = pd.ExcelFile('examples/ex1.xlsx')\n",
    "pd.read_excel(xlsx, 'Sheet1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-western",
   "metadata": {},
   "source": [
    "Alternatively, you can also simply pass the filename to `pandas.read_excel()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "timely-imperial",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('examples/ex2.xlsx')\n",
    "frame.to_excel(writer, 'Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-johns",
   "metadata": {},
   "source": [
    "Likewise in the earlier example, you can also a file path to `to_excel()` method and avoid creating an `ExcelWriter` instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "functional-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.to_excel('examples/ex2.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-staff",
   "metadata": {},
   "source": [
    "## Interacting with Web APIs\n",
    "\n",
    "Many websites have public APIs providing data feeds via JSON or some other format. There are a number of ways to access these APIs from Python: one easy-to-use method that I recommend is the `requests` package. \n",
    "\n",
    "To illustrate an example where we want to find the last 30 GitHub issues for pandas on GitHub, we can make a `GET HTTP` request using the add-on `requests` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "naked-graphic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://api.github.com/repos/pandas-dev/pandas/issues'\n",
    "resp = requests.get(url)\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-disaster",
   "metadata": {},
   "source": [
    "The Response object's `json()` method will return a dictionary containing JSON parsed into native Python objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "several-florida",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Update type hints for ExtensionArray and ExtensionDtype'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = resp.json()\n",
    "data[0]['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-superior",
   "metadata": {},
   "source": [
    "Each element in data is a dictionary containing all of the data found on a GitHub issue page (except for the comments). We can pass the data directly to DataFrame and extract fields of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "expensive-electron",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>title</th>\n",
       "      <th>labels</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39501</td>\n",
       "      <td>Update type hints for ExtensionArray and Exten...</td>\n",
       "      <td>[]</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39500</td>\n",
       "      <td>DOC: add example to insert (#39313)</td>\n",
       "      <td>[]</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39499</td>\n",
       "      <td>BUG: use of partition_cols raises incompatibil...</td>\n",
       "      <td>[{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ=...</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39498</td>\n",
       "      <td>REF: Move agg helpers into apply</td>\n",
       "      <td>[{'id': 697792067, 'node_id': 'MDU6TGFiZWw2OTc...</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39497</td>\n",
       "      <td>ENH: Enable parsing of ISO8601-like timestamps...</td>\n",
       "      <td>[]</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number                                              title  \\\n",
       "0   39501  Update type hints for ExtensionArray and Exten...   \n",
       "1   39500                DOC: add example to insert (#39313)   \n",
       "2   39499  BUG: use of partition_cols raises incompatibil...   \n",
       "3   39498                   REF: Move agg helpers into apply   \n",
       "4   39497  ENH: Enable parsing of ISO8601-like timestamps...   \n",
       "\n",
       "                                              labels state  \n",
       "0                                                 []  open  \n",
       "1                                                 []  open  \n",
       "2  [{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ=...  open  \n",
       "3  [{'id': 697792067, 'node_id': 'MDU6TGFiZWw2OTc...  open  \n",
       "4                                                 []  open  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues = pd.DataFrame(data, columns=['number','title','labels','state'])\n",
    "issues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-coffee",
   "metadata": {},
   "source": [
    "## Interacting with Databases\n",
    "\n",
    "In a business setting, most data may not be stored in text or Excel files. SQL-based relational databases (such as SQL Server, PostgreSQL, and MySQL) are in wide use, and many alternative databases have become quite popular.\n",
    "\n",
    "Loading data from SQL into a DataFrame is fairly straightforwrd, and pandas has some functions to simplify the process. As an example, I'll create a SQLLite database using Python's built-in `sqlite3` driver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "adverse-promise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7f7280fd48f0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "query = \"\"\"\n",
    "CREATE TABLE test\n",
    "(a VARCHAR(20), b VARCHAR(20),\n",
    " c REAL,        d INTEGER\n",
    ");\"\"\"\n",
    "\n",
    "con = sqlite3.connect('examples/mydata.sqlite')\n",
    "\n",
    "con.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-hunger",
   "metadata": {},
   "source": [
    "After creating the database and table, we can insert a few rows of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "major-falls",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [('Atlanta', 'Georgia', 1.25, 6),\n",
    "        ('Tallahassee', 'Florida', 2.6, 3),\n",
    "        ('Sacramento', 'California', 1.7, 5)]\n",
    "\n",
    "stmt = \"INSERT INTO test VALUES(?, ?, ?, ?)\"\n",
    "con.executemany(stmt, data)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "established-kruger",
   "metadata": {},
   "source": [
    "Most Python SQL drivers (PyODBC, psycopg2, MySQLdb, pymssql, etc.) return a list of tuples when selecting data from a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "light-favor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Atlanta', 'Georgia', 1.25, 6),\n",
       " ('Tallahassee', 'Florida', 2.6, 3),\n",
       " ('Sacramento', 'California', 1.7, 5)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor = con.execute('select * from test')\n",
    "rows = cursor.fetchall()\n",
    "rows      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-writing",
   "metadata": {},
   "source": [
    "You can pass the list of tuples to the DataFrame constructor, but you also need the column names, which can be extracted from cursor's `description` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "classified-function",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('a', None, None, None, None, None, None),\n",
       " ('b', None, None, None, None, None, None),\n",
       " ('c', None, None, None, None, None, None),\n",
       " ('d', None, None, None, None, None, None))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dangerous-cleaning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>1.25</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tallahassee</td>\n",
       "      <td>Florida</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sacramento</td>\n",
       "      <td>California</td>\n",
       "      <td>1.70</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             a           b     c  d\n",
       "0      Atlanta     Georgia  1.25  6\n",
       "1  Tallahassee     Florida  2.60  3\n",
       "2   Sacramento  California  1.70  5"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rows, columns=[x[0] for x in cursor.description])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resident-anthony",
   "metadata": {},
   "source": [
    "The SQLAlchemy project is a popular Python SQL toolkit that abstracts away many of the common differences between SQL databases. pandas has a `read_sql()` function that enables you to read data easily from a general SQLAlchemy connection. Here, we'll connect to the same SQLite database with SQLAlchemy and read data from the table created before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "brave-absorption",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>1.25</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tallahassee</td>\n",
       "      <td>Florida</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sacramento</td>\n",
       "      <td>California</td>\n",
       "      <td>1.70</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             a           b     c  d\n",
       "0      Atlanta     Georgia  1.25  6\n",
       "1  Tallahassee     Florida  2.60  3\n",
       "2   Sacramento  California  1.70  5"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlalchemy as sqla\n",
    "\n",
    "db = sqla.create_engine('sqlite:///examples/mydata.sqlite')\n",
    "pd.read_sql('select * from test', db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-listening",
   "metadata": {},
   "source": [
    "Next up, we'll learn about [indexing, selecting and assigning](https://github.com/colintwh/python-analysis/blob/master/indexing.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
